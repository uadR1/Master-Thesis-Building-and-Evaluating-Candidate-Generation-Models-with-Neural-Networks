{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas, Numpy\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf \n",
    "\n",
    "# RBM from Recommenders\n",
    "from recommenders.models.rbm.rbm import RBM \n",
    "from recommenders.utils.timer import Timer \n",
    "from recommenders.utils.plot import line_graph \n",
    "\n",
    "# Affinity Matrix \n",
    "from recommenders.datasets.sparse import AffinityMatrix\n",
    "\n",
    "# Evaluation \n",
    "from recommenders.evaluation.python_evaluation import (\n",
    "    precision_at_k,\n",
    "    recall_at_k\n",
    ")\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# Visualization\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Train & Test Data\n",
    "train = pd.read_csv(\"../../00_Data/online_retail_ratings_train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"../../00_Data/online_retail_ratings_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train: (357692, 3)\n",
      "Shape of Test: \t (89479, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check Shapes\n",
    "print(\"Shape of Train:\", train.shape)\n",
    "print(\"Shape of Test: \\t\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Users in Train: 3696\n",
      "Unique Users in Test: 3696\n",
      "Unique Items in Train: 2769\n",
      "Unique Items in Test: 2769\n"
     ]
    }
   ],
   "source": [
    "# Check Number of Unique Items and User in Train & Test \n",
    "print(\"Unique Users in Train:\", train.CustomerID.nunique())\n",
    "print(\"Unique Users in Test:\", test.CustomerID.nunique())\n",
    "print(\"Unique Items in Train:\", train.StockCode.nunique())\n",
    "print(\"Unique Items in Test:\", test.StockCode.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    153304\n",
       "-1    149998\n",
       " 2     48666\n",
       "-2      5724\n",
       "Name: purchased, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value Counts of Ratings in Train\n",
    "train.purchased.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    38373\n",
       "-1    37499\n",
       " 2    12174\n",
       "-2     1433\n",
       "Name: purchased, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value Counts of Ratings in Test\n",
    "test.purchased.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclude negative Ratings for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    153304\n",
       "2     48666\n",
       "Name: purchased, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude negative Ratings from Train  \n",
    "train = train[train['purchased']>0]\n",
    "\n",
    "# Show Impact \n",
    "train.purchased.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    38373\n",
       "2    12174\n",
       "Name: purchased, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude negative Ratings from test  \n",
    "test = test[test['purchased']>0]\n",
    "\n",
    "# Show Impact \n",
    "test.purchased.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the same items and users are in both sets \n",
    "# Find the set of unique items in both the train and test sets\n",
    "train_users = set(train['CustomerID'].unique())\n",
    "test_users = set(test['CustomerID'].unique())\n",
    "\n",
    "# Find the intersection of the sets from step 1\n",
    "common_items = train_users.intersection(test_users)\n",
    "\n",
    "# Filter the train and test sets to include only the rows with item IDs that are in the intersection set\n",
    "train = train[train['CustomerID'].isin(common_items)]\n",
    "test = test[test['CustomerID'].isin(common_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the same items and users are in both sets \n",
    "# Find the set of unique items in both the train and test sets\n",
    "train_items = set(train['StockCode'].unique())\n",
    "test_items = set(test['StockCode'].unique())\n",
    "\n",
    "# Find the intersection of the sets from step 1\n",
    "common_items = train_items.intersection(test_items)\n",
    "\n",
    "# Filter the train and test sets to include only the rows with item IDs that are in the intersection set\n",
    "train = train[train['StockCode'].isin(common_items)]\n",
    "test = test[test['StockCode'].isin(common_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Users in Train: 3643\n",
      "Unique Users in Test: 3643\n",
      "Unique Items in Train: 2765\n",
      "Unique Items in Test: 2765\n"
     ]
    }
   ],
   "source": [
    "# Check Number of Unique Items and User in Train & Test \n",
    "print(\"Unique Users in Train:\", train.CustomerID.nunique())\n",
    "print(\"Unique Users in Test:\", test.CustomerID.nunique())\n",
    "print(\"Unique Items in Train:\", train.StockCode.nunique())\n",
    "print(\"Unique Items in Test:\", test.StockCode.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Datasets for Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set standard names for the analysis \n",
    "header = {\n",
    "        \"col_user\": \"CustomerID\",\n",
    "        \"col_item\": \"StockCode\",\n",
    "        \"col_rating\": \"purchased\",\n",
    "    }\n",
    "\n",
    "# Instantiate the sparse matrix generation  \n",
    "am_train = AffinityMatrix(df = train, col_user='CustomerID', col_item='StockCode', col_rating='purchased')\n",
    "am_test = AffinityMatrix(df = test, col_user='CustomerID', col_item='StockCode', col_rating='purchased')\n",
    "\n",
    "# Obtain the sparse matrix \n",
    "Xtr, _, _ = am_train.gen_affinity_matrix()\n",
    "Xtst, _, _ = am_test.gen_affinity_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3643, 2765)\n",
      "(3643, 2765)\n"
     ]
    }
   ],
   "source": [
    "# Sanity Check: Print Shape of Train & Test Matrix - Do numbers match nr of unique users and items from above \n",
    "print(Xtr.shape)\n",
    "print(Xtst.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Xtr & Xtst After reloading & Transformation\n",
    "print(np.unique(Xtr))\n",
    "print(np.unique(Xtst))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at 10 for  500 neurons: 0.03296430067342124\n",
      "Recall at 10 for  500 neurons: 0.03315551997038836\n",
      "Recall at 10 for  500 neurons: 0.03302470214545035\n",
      "Recall at 10 for  500 neurons: 0.032110649640947356\n",
      "Recall at 10 for  500 neurons: 0.03147368098527063\n",
      "Recall at 10 for  500 neurons: 0.033319262921085765\n",
      "Recall at 10 for  600 neurons: 0.048356811914426076\n",
      "Recall at 10 for  600 neurons: 0.04867442371518753\n",
      "Recall at 10 for  600 neurons: 0.053020576134617685\n",
      "Recall at 10 for  600 neurons: 0.04563459300633603\n",
      "Recall at 10 for  600 neurons: 0.04498903991138204\n",
      "Recall at 10 for  600 neurons: 0.04797919220137193\n",
      "Recall at 10 for  700 neurons: 0.05484474999225608\n",
      "Recall at 10 for  700 neurons: 0.0515469594906076\n",
      "Recall at 10 for  700 neurons: 0.05018884205430742\n",
      "Recall at 10 for  700 neurons: 0.058727707178232405\n",
      "Recall at 10 for  700 neurons: 0.06016475560912275\n",
      "Recall at 10 for  700 neurons: 0.05579373528837845\n",
      "Recall at 10 for  800 neurons: 0.051207377042176455\n",
      "Recall at 10 for  800 neurons: 0.05029061412839327\n",
      "Recall at 10 for  800 neurons: 0.04575263445568728\n",
      "Recall at 10 for  800 neurons: 0.05465740014932923\n",
      "Recall at 10 for  800 neurons: 0.05260265773020668\n",
      "Recall at 10 for  800 neurons: 0.05156846730205323\n",
      "Recall at 10 for  900 neurons: 0.05314950752657321\n",
      "Recall at 10 for  900 neurons: 0.053398612616516246\n",
      "Recall at 10 for  900 neurons: 0.049203848031134305\n",
      "Recall at 10 for  900 neurons: 0.05470251979235975\n",
      "Recall at 10 for  900 neurons: 0.05429597307464202\n",
      "Recall at 10 for  900 neurons: 0.05561130835998472\n",
      "Recall at 10 for  1000 neurons: 0.0810150262516733\n",
      "Recall at 10 for  1000 neurons: 0.08739199696096886\n",
      "Recall at 10 for  1000 neurons: 0.10059037194208881\n",
      "Recall at 10 for  1000 neurons: 0.07314947027992096\n",
      "Recall at 10 for  1000 neurons: 0.07455235918493516\n",
      "Recall at 10 for  1000 neurons: 0.08282183778736853\n",
      "Recall at 10 for  1100 neurons: 0.14594081145824614\n",
      "Recall at 10 for  1100 neurons: 0.16326337650407596\n",
      "Recall at 10 for  1100 neurons: 0.17129726997461445\n",
      "Recall at 10 for  1100 neurons: 0.11269502944467756\n",
      "Recall at 10 for  1100 neurons: 0.13186918163349148\n",
      "Recall at 10 for  1100 neurons: 0.14713637377403463\n",
      "Recall at 10 for  1200 neurons: 0.0886070932105046\n",
      "Recall at 10 for  1200 neurons: 0.08044569068025863\n",
      "Recall at 10 for  1200 neurons: 0.07475175518237731\n",
      "Recall at 10 for  1200 neurons: 0.09757812654390137\n",
      "Recall at 10 for  1200 neurons: 0.09406298362535806\n",
      "Recall at 10 for  1200 neurons: 0.09317959388910985\n",
      "Recall at 10 for  1300 neurons: 0.13931895930673927\n",
      "Recall at 10 for  1300 neurons: 0.1614779223644537\n",
      "Recall at 10 for  1300 neurons: 0.17176522205472106\n",
      "Recall at 10 for  1300 neurons: 0.11436860226850172\n",
      "Recall at 10 for  1300 neurons: 0.12892495067194007\n",
      "Recall at 10 for  1300 neurons: 0.14094162275764288\n",
      "Recall at 10 for  1400 neurons: 0.1219339719609753\n",
      "Recall at 10 for  1400 neurons: 0.1315106330648236\n",
      "Recall at 10 for  1400 neurons: 0.13942516533208943\n",
      "Recall at 10 for  1400 neurons: 0.12126350197193417\n",
      "Recall at 10 for  1400 neurons: 0.12353638608751878\n",
      "Recall at 10 for  1400 neurons: 0.12702009477125645\n",
      "Recall at 10 for  1500 neurons: 0.11588030617910391\n",
      "Recall at 10 for  1500 neurons: 0.11540709167747923\n",
      "Recall at 10 for  1500 neurons: 0.12004440551441227\n",
      "Recall at 10 for  1500 neurons: 0.1128215238436011\n",
      "Recall at 10 for  1500 neurons: 0.11361203074484882\n",
      "Recall at 10 for  1500 neurons: 0.11568654192562143\n"
     ]
    }
   ],
   "source": [
    "# Set up Parameters \n",
    "hidden_neurons = [500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500]\n",
    "batch = [200, 300]\n",
    "lrate = [0.002, 0.003, 0.004]\n",
    "\n",
    "# Initiate Lists for Assessment\n",
    "recall_10 = []\n",
    "recall_20 = []\n",
    "precision_10 = []\n",
    "precision_20 = []\n",
    "neurons = []\n",
    "batches = []\n",
    "learning_rates = []\n",
    "\n",
    "# Loop through lists of parameters \n",
    "\n",
    "for n in hidden_neurons:\n",
    "    for b in batch:\n",
    "        for l in lrate:\n",
    "            # Delete Model First\n",
    "            try:\n",
    "                del(model)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Define Model with Parameters\n",
    "            model = RBM(\n",
    "                possible_ratings=np.setdiff1d(np.unique(Xtr), np.array([0])), # Always provide this range - way better results! \n",
    "                visible_units=Xtr.shape[1],\n",
    "                hidden_units=n,\n",
    "                training_epoch=30,\n",
    "                minibatch_size=b,\n",
    "                keep_prob=0.7,\n",
    "                with_metrics=True,\n",
    "                learning_rate=l,\n",
    "                seed=42\n",
    "            )\n",
    "            \n",
    "            # Fit Model \n",
    "            model.fit(Xtr)\n",
    "            \n",
    "            # Recommend top k\n",
    "            top_k = model.recommend_k_items(Xtst, top_k=20, remove_seen=True)\n",
    "            \n",
    "            # Map Back Xtst & Top K\n",
    "            top_k_df = am_test.map_back_sparse(top_k, kind = 'prediction')\n",
    "            test_df  = am_test.map_back_sparse(Xtst, kind='ratings')\n",
    "            \n",
    "            # Evaluation \n",
    "            recall_at_ten  = recall_at_k(test_df, top_k_df, col_user=\"CustomerID\", col_item=\"StockCode\", \n",
    "                                    col_rating=\"purchased\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\", k=10)\n",
    "            recall_at_twenty = recall_at_k(test_df, top_k_df, col_user=\"CustomerID\", col_item=\"StockCode\", \n",
    "                                    col_rating=\"purchased\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\", k=20)\n",
    "            precision_at_ten = precision_at_k(test_df, top_k_df, col_user='CustomerID', col_item='StockCode',\n",
    "                                            col_rating ='purchased', col_prediction=\"prediction\",\n",
    "                                            relevancy_method='top_k', k = 10)\n",
    "            precision_at_twenty = precision_at_k(test_df, top_k_df, col_user='CustomerID', col_item='StockCode',\n",
    "                                col_rating ='purchased', col_prediction=\"prediction\",\n",
    "                                relevancy_method='top_k', k = 20)\n",
    "            \n",
    "            # Append lists \n",
    "            recall_10.append(recall_at_ten)\n",
    "            recall_20.append(recall_at_twenty)\n",
    "            precision_10.append(precision_at_ten)\n",
    "            precision_20.append(precision_at_twenty)\n",
    "            neurons.append(n)\n",
    "            batches.append(b)\n",
    "            learning_rates.append(l)\n",
    "            \n",
    "            # Print Results \n",
    "            print(\"Recall at 10 for \", n, \"neurons:\", recall_at_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_neurons</th>\n",
       "      <th>minibatches</th>\n",
       "      <th>learning_rates</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>recall@20</th>\n",
       "      <th>precision@10</th>\n",
       "      <th>precision@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1300</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.171765</td>\n",
       "      <td>0.237026</td>\n",
       "      <td>0.206478</td>\n",
       "      <td>0.145745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.171297</td>\n",
       "      <td>0.238259</td>\n",
       "      <td>0.199780</td>\n",
       "      <td>0.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1100</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.163263</td>\n",
       "      <td>0.229461</td>\n",
       "      <td>0.189569</td>\n",
       "      <td>0.136248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1300</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.161478</td>\n",
       "      <td>0.226501</td>\n",
       "      <td>0.196102</td>\n",
       "      <td>0.140255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1100</td>\n",
       "      <td>300</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.147136</td>\n",
       "      <td>0.209359</td>\n",
       "      <td>0.168982</td>\n",
       "      <td>0.123634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.033156</td>\n",
       "      <td>0.054704</td>\n",
       "      <td>0.043069</td>\n",
       "      <td>0.036152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.033025</td>\n",
       "      <td>0.055081</td>\n",
       "      <td>0.043920</td>\n",
       "      <td>0.036453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>200</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.032964</td>\n",
       "      <td>0.054278</td>\n",
       "      <td>0.042575</td>\n",
       "      <td>0.035232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.032111</td>\n",
       "      <td>0.054122</td>\n",
       "      <td>0.041806</td>\n",
       "      <td>0.034271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>300</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.031474</td>\n",
       "      <td>0.052276</td>\n",
       "      <td>0.041669</td>\n",
       "      <td>0.033997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hidden_neurons  minibatches  learning_rates  recall@10  recall@20  \\\n",
       "50            1300          200           0.004   0.171765   0.237026   \n",
       "38            1100          200           0.004   0.171297   0.238259   \n",
       "37            1100          200           0.003   0.163263   0.229461   \n",
       "49            1300          200           0.003   0.161478   0.226501   \n",
       "41            1100          300           0.004   0.147136   0.209359   \n",
       "..             ...          ...             ...        ...        ...   \n",
       "1              500          200           0.003   0.033156   0.054704   \n",
       "2              500          200           0.004   0.033025   0.055081   \n",
       "0              500          200           0.002   0.032964   0.054278   \n",
       "3              500          300           0.002   0.032111   0.054122   \n",
       "4              500          300           0.003   0.031474   0.052276   \n",
       "\n",
       "    precision@10  precision@20  \n",
       "50      0.206478      0.145745  \n",
       "38      0.199780      0.142300  \n",
       "37      0.189569      0.136248  \n",
       "49      0.196102      0.140255  \n",
       "41      0.168982      0.123634  \n",
       "..           ...           ...  \n",
       "1       0.043069      0.036152  \n",
       "2       0.043920      0.036453  \n",
       "0       0.042575      0.035232  \n",
       "3       0.041806      0.034271  \n",
       "4       0.041669      0.033997  \n",
       "\n",
       "[66 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe out of the Results of the Hyperparameter Tuning \n",
    "df_tuning_1 = pd.DataFrame({\n",
    "    \"hidden_neurons\": neurons,\n",
    "    \"minibatches\": batches,\n",
    "    \"learning_rates\":learning_rates,\n",
    "    \"recall@10\": recall_10,\n",
    "    \"recall@20\": recall_20,\n",
    "    \"precision@10\":precision_10,\n",
    "    \"precision@20\":precision_20\n",
    "})\n",
    "# Sort Values by recall@10 \n",
    "df_tuning_1.sort_values(by='recall@10', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17afcd9f6960de0a3656d2c4c5dd434deed0eab3cd38c55c3169df3bef50250d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
