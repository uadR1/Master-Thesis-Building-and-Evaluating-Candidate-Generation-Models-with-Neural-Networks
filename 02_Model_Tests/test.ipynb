{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx'\n",
    "data = pd.read_excel(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data = data[data['Quantity'] > 0]\n",
    "data = data[['CustomerID', 'StockCode']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = data['CustomerID'].unique()\n",
    "customer_to_idx = {old: new for new, old in enumerate(customers)}\n",
    "\n",
    "items = data['StockCode'].unique()\n",
    "item_to_idx = {old: new for new, old in enumerate(items)}\n",
    "\n",
    "data['CustomerID'] = data['CustomerID'].apply(lambda x: customer_to_idx[x])\n",
    "data['StockCode'] = data['StockCode'].apply(lambda x: item_to_idx[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM(object):\n",
    "    def __init__(self, visible_dim, hidden_dim):\n",
    "        self.visible_dim = visible_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = tf.Variable(tf.random.normal(shape=(self.visible_dim, self.hidden_dim)))\n",
    "        self.v_bias = tf.Variable(tf.zeros(shape=[self.visible_dim]))\n",
    "        self.h_bias = tf.Variable(tf.zeros(shape=[self.hidden_dim]))\n",
    "\n",
    "    def prob_h_given_v(self, visible):\n",
    "        return tf.nn.sigmoid(tf.matmul(visible, self.W) + self.h_bias)\n",
    "\n",
    "    def prob_v_given_h(self, hidden):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(self.W)) + self.v_bias)\n",
    "\n",
    "    def sample_h_given_v(self, visible):\n",
    "        visible = tf.cast(visible, tf.float32)\n",
    "        visible = tf.reshape(visible, [visible.shape[0], visible.shape[1]])\n",
    "        return tf.nn.relu(tf.sign(self.prob_h_given_v(visible) - tf.random.uniform(tf.shape(visible),minval=0, maxval=1)))\n",
    "\n",
    "\n",
    "    def sample_v_given_h(self, hidden):\n",
    "        return tf.nn.relu(tf.sign(self.prob_v_given_h(hidden) - tf.random.uniform(tf.shape(hidden))))\n",
    "\n",
    "    def gibbs_sampling(self, visible):\n",
    "        h = self.sample_h_given_v(visible)\n",
    "        v = self.sample_v_given_h(h)\n",
    "        return v\n",
    "\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        data = data.astype('int32')\n",
    "        data = np.clip(data, 0, self.visible_dim-1)\n",
    "        return data\n",
    "\n",
    "    def train(self, data, epochs=10, batch_size=64, lr=0.01):\n",
    "        data = self.prepare_data(data)\n",
    "        num_batches = len(data) // batch_size\n",
    "        optimizer = tf.optimizers.Adam(lr)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(data)\n",
    "\n",
    "            for i in range(num_batches):\n",
    "                batch = data[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    positive_phase = batch\n",
    "                    negative_phase = self.gibbs_sampling(positive_phase)\n",
    "\n",
    "                    positive_energy = tf.reduce_mean(tf.reduce_sum(tf.multiply(self.W, positive_phase), axis=1)) \\\n",
    "                                    + tf.reduce_mean(tf.multiply(self.v_bias, positive_phase)) \\\n",
    "                                    + tf.reduce_mean(tf.multiply(self.h_bias, self.prob_h_given_v(positive_phase)))\n",
    "\n",
    "                    negative_energy = tf.reduce_mean(tf.reduce_sum(tf.multiply(self.W, negative_phase), axis=1)) \\\n",
    "                                    + tf.reduce_mean(tf.multiply(self.v_bias, negative_phase)) \\\n",
    "                                    + tf.reduce_mean(tf.multiply(self.h_bias, self.prob_h_given_v(negative_phase)))\n",
    "\n",
    "                    loss = positive_energy - negative_energy\n",
    "\n",
    "                grads = tape.gradient(loss, [self.W, self.v_bias, self.h_bias])\n",
    "                optimizer.apply_gradients(zip(grads, [self.W, self.v_bias, self.h_bias]))\n",
    "\n",
    "\n",
    "    def predict(self, user_idx, item_indices):\n",
    "        user_input = np.zeros((len(item_indices), self.visible_dim))\n",
    "        user_input[:, user_idx] = 1\n",
    "        item_input = np.zeros((len(item_indices), self.visible_dim))\n",
    "        item_input[:, item_indices] = 1\n",
    "\n",
    "        hidden_prob = self.prob_h_given_v(item_input)\n",
    "        user_prob = tf.matmul(hidden_prob, tf.transpose(tf.cast(tf.expand_dims(user_input, axis=0), tf.float32)))\n",
    "        user_ranking = tf.argsort(user_prob, direction='DESCENDING')\n",
    "\n",
    "        return user_ranking\n",
    "    \n",
    "    def evaluate_precision_recall_at_k(self, test_data, k=10):\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "\n",
    "        for user in test_data['CustomerID'].unique():\n",
    "            user_items = test_data[test_data['CustomerID'] == user]['StockCode'].tolist()\n",
    "            if len(user_items) == 0:\n",
    "                continue\n",
    "            item_indices = np.arange(self.visible_dim)\n",
    "            user_idx = self.customer_to_idx[user]\n",
    "            predictions = self.predict(user_idx, item_indices)\n",
    "            predictions = [i.numpy() for i in predictions]\n",
    "            user_recommendations = [item for item in predictions if item not in user_items][:k]\n",
    "            if len(user_recommendations) == 0:\n",
    "                continue\n",
    "            true_positives = len(set(user_recommendations).intersection(set(user_items)))\n",
    "            precision = true_positives / k\n",
    "            recall = true_positives / len(user_items)\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "\n",
    "        precision = np.mean(precision_list)\n",
    "        recall = np.mean(recall_list)\n",
    "\n",
    "        return precision, recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [64,2], In[1]: [3665,50] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m rbm \u001b[39m=\u001b[39m RBM(visible_dim, hidden_dim)\n\u001b[1;32m      5\u001b[0m rbm\u001b[39m.\u001b[39mcustomer_to_idx \u001b[39m=\u001b[39m customer_to_idx\n\u001b[0;32m----> 6\u001b[0m rbm\u001b[39m.\u001b[39;49mtrain(train_data\u001b[39m.\u001b[39;49mvalues, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Evaluate the model's precision and recall at k\u001b[39;00m\n\u001b[1;32m      9\u001b[0m precision, recall \u001b[39m=\u001b[39m rbm\u001b[39m.\u001b[39mevaluate_precision_recall_at_k(test_data, k\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 48\u001b[0m, in \u001b[0;36mRBM.train\u001b[0;34m(self, data, epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m     47\u001b[0m     positive_phase \u001b[39m=\u001b[39m batch\n\u001b[0;32m---> 48\u001b[0m     negative_phase \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgibbs_sampling(positive_phase)\n\u001b[1;32m     50\u001b[0m     positive_energy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mreduce_sum(tf\u001b[39m.\u001b[39mmultiply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW, positive_phase), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)) \\\n\u001b[1;32m     51\u001b[0m                     \u001b[39m+\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mmultiply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_bias, positive_phase)) \\\n\u001b[1;32m     52\u001b[0m                     \u001b[39m+\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mmultiply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh_bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprob_h_given_v(positive_phase)))\n\u001b[1;32m     54\u001b[0m     negative_energy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mreduce_sum(tf\u001b[39m.\u001b[39mmultiply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW, negative_phase), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)) \\\n\u001b[1;32m     55\u001b[0m                     \u001b[39m+\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mmultiply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_bias, negative_phase)) \\\n\u001b[1;32m     56\u001b[0m                     \u001b[39m+\u001b[39m tf\u001b[39m.\u001b[39mreduce_mean(tf\u001b[39m.\u001b[39mmultiply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh_bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprob_h_given_v(negative_phase)))\n",
      "Cell \u001b[0;32mIn[31], line 25\u001b[0m, in \u001b[0;36mRBM.gibbs_sampling\u001b[0;34m(self, visible)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgibbs_sampling\u001b[39m(\u001b[39mself\u001b[39m, visible):\n\u001b[0;32m---> 25\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_h_given_v(visible)\n\u001b[1;32m     26\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_v_given_h(h)\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m v\n",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m, in \u001b[0;36mRBM.sample_h_given_v\u001b[0;34m(self, visible)\u001b[0m\n\u001b[1;32m     16\u001b[0m visible \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(visible, tf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     17\u001b[0m visible \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(visible, [visible\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], visible\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]])\n\u001b[0;32m---> 18\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu(tf\u001b[39m.\u001b[39msign(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprob_h_given_v(visible) \u001b[39m-\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(tf\u001b[39m.\u001b[39mshape(visible),minval\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, maxval\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "Cell \u001b[0;32mIn[31], line 10\u001b[0m, in \u001b[0;36mRBM.prob_h_given_v\u001b[0;34m(self, visible)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprob_h_given_v\u001b[39m(\u001b[39mself\u001b[39m, visible):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msigmoid(tf\u001b[39m.\u001b[39;49mmatmul(visible, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mW) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mh_bias)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recom/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recom/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:3314\u001b[0m, in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   3312\u001b[0m   \u001b[39mreturn\u001b[39;00m ret\n\u001b[1;32m   3313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3314\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_math_ops\u001b[39m.\u001b[39;49mmat_mul(\n\u001b[1;32m   3315\u001b[0m       a, b, transpose_a\u001b[39m=\u001b[39;49mtranspose_a, transpose_b\u001b[39m=\u001b[39;49mtranspose_b, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recom/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:5532\u001b[0m, in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5530\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   5531\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 5532\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   5533\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   5534\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/recom/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:6862\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m message \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6861\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 6862\u001b[0m six\u001b[39m.\u001b[39;49mraise_from(core\u001b[39m.\u001b[39;49m_status_to_exception(e\u001b[39m.\u001b[39;49mcode, message), \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [64,2], In[1]: [3665,50] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "# Create an instance of the RBM class and train the model\n",
    "visible_dim = len(items)\n",
    "hidden_dim = 50\n",
    "rbm = RBM(visible_dim, hidden_dim)\n",
    "rbm.customer_to_idx = customer_to_idx\n",
    "rbm.train(train_data.values, epochs=20, batch_size=64, lr=0.01)\n",
    "\n",
    "# Evaluate the model's precision and recall at k\n",
    "precision, recall = rbm.evaluate_precision_recall_at_k(test_data, k=10)\n",
    "\n",
    "print('Precision at k = 10:', precision)\n",
    "print('Recall at k = 10:', recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17afcd9f6960de0a3656d2c4c5dd434deed0eab3cd38c55c3169df3bef50250d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
