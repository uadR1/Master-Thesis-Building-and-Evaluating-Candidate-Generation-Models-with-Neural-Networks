{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas & Numpy \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Suprise & Recommenders \n",
    "import surprise \n",
    "from recommenders.models.surprise.surprise_utils import compute_ranking_predictions, predict\n",
    "from recommenders.evaluation.python_evaluation import precision_at_k, recall_at_k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Train & Test Data\n",
    "train = pd.read_csv(\"../../00_Data/online_retail_ratings_train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"../../00_Data/online_retail_ratings_test.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train: (349978, 3)\n",
      "Shape of Test: \t (87558, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check Shapes\n",
    "print(\"Shape of Train:\", train.shape)\n",
    "print(\"Shape of Test: \\t\", test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of Train Dataset for Surprise Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reader \n",
    "reader = surprise.Reader(rating_scale=(-2,2))\n",
    "\n",
    "# Build Train Set from Custom Dataset\n",
    "train_set = surprise.Dataset.load_from_df(train[['CustomerID', 'StockCode', 'purchased']], reader=reader).build_full_trainset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x7fa1a8e5d1c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete Model first \n",
    "try:\n",
    "    del(basemodel)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create Object for Model\n",
    "basemodel = surprise.NMF(random_state=0, verbose=False, n_factors=10, n_epochs=50, reg_pu=0.1, reg_qi=0.1)\n",
    "\n",
    "# Fit Model\n",
    "basemodel.fit(train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: Test Set only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Test Only\n",
    "test_pred = predict(basemodel, test, usercol='CustomerID', itemcol='StockCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    87558.000000\n",
       "mean         0.058892\n",
       "std          0.541396\n",
       "min         -2.000000\n",
       "25%         -0.026785\n",
       "50%          0.001746\n",
       "75%          0.132778\n",
       "max          2.000000\n",
       "Name: prediction, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Range of predicions\n",
    "test_pred.prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Predictions\n",
    "test_pred['prediction'] = np.where((test_pred['prediction']>0),1,0)\n",
    "\n",
    "# Convert Test\n",
    "test['purchased'] = np.where((test['purchased']>0),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Distribution\n",
    "test_pred['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort Index of both Datasets to use Accuracy Score \n",
    "test = test.sort_values(by=['CustomerID', 'StockCode'])\n",
    "test_pred = test_pred.sort_values(by=['CustomerID', 'StockCode'])\n",
    "\n",
    "# Reset indeces for both DataFrames\n",
    "test = test.reset_index(drop=True)\n",
    "test_pred = test_pred.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Reorder columns for test \n",
    "test = test[['CustomerID', 'StockCode', 'purchased']]\n",
    "# Head of Test\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head of Test_pred\n",
    "test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Accuracy \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Accuracy \n",
    "accuracy_score(test.purchased, test_pred.prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction: Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict All Pairs of Users & Items that are NOT in the Trainset \n",
    "predictions = compute_ranking_predictions(basemodel, train, usercol='CustomerID', itemcol='StockCode', remove_seen=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write function to filter out top N \n",
    "def filter_top_n(predictions: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    \n",
    "    # Group the dataframe by 'CustomerID', and for each group, sort by 'prediction' in descending order, then take the top N rows\n",
    "    top_n_per_customer = predictions.groupby('CustomerID', group_keys=False).apply(lambda group: group.sort_values('prediction', ascending=False).head(n))\n",
    "    \n",
    "    return top_n_per_customer\n",
    "\n",
    "# Filter Top 10 \n",
    "top_10 = filter_top_n(predictions, 10)\n",
    "\n",
    "# Filter Top 20 \n",
    "top_20 = filter_top_n(predictions, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall at 10 \t: 0.0017577644496014988\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Precision at 10 \n",
    "eval_precision_10 = precision_at_k(test, top_10, col_user=\"CustomerID\", col_item=\"StockCode\",\n",
    "                                    col_rating=\"purchased\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\", k=10)\n",
    "print('precision at 10 \\t:', eval_precision_10)\n",
    "\n",
    "# Evaluate Recall at 10 \n",
    "eval_recall_10 = recall_at_k(test, top_10,col_user=\"CustomerID\", col_item=\"StockCode\",\n",
    "                                    col_rating=\"purchased\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\", k=10)\n",
    "print('recall at 10 \\t:', eval_recall_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Precision at 20 \n",
    "eval_precision_20 = precision_at_k(test, top_20, col_user=\"CustomerID\", col_item=\"StockCode\",\n",
    "                                    col_rating=\"purchased\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\", k=20)\n",
    "print('precision at 20 \\t:', eval_precision_20)\n",
    "\n",
    "# Evaluate Recall at 20 \n",
    "eval_recall_20 = recall_at_k(test, top_20,col_user=\"CustomerID\", col_item=\"StockCode\",\n",
    "                                    col_rating=\"purchased\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\", k=20)\n",
    "print('recall at 20 \\t:', eval_recall_20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall at for 20 factors: \t 0.003002190400353022\n",
      "recall at for 2000 factors: \t 0.003002190400353022\n"
     ]
    }
   ],
   "source": [
    "# Define Set of Hyperparameters \n",
    "n_factors = [20, 2000]\n",
    "reg_bu = [0.01]\n",
    "reg_bi = [0.01]\n",
    "lr_bu = [0.001]\n",
    "lr_bi = [0.001]\n",
    "\n",
    "# Initiate Lists \n",
    "factor_nr = []\n",
    "regulation_user = []\n",
    "regulation_item = []\n",
    "lr_user = []\n",
    "lr_item = []\n",
    "recall_10 = []\n",
    "\n",
    "for factors in n_factors:\n",
    "    for reg_user in reg_bu:\n",
    "        for reg_item in reg_bi:\n",
    "            for learning_user in lr_bu:\n",
    "                for learning_item in lr_bi:\n",
    "                    try:\n",
    "                        del(model)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # Define Model \n",
    "                    model = surprise.NMF(random_state=0,\n",
    "                                        verbose=False,\n",
    "                                        biased=False,\n",
    "                                        n_factors=factors,\n",
    "                                        n_epochs=20,\n",
    "                                        reg_bu=reg_user,\n",
    "                                        reg_bi=reg_item,\n",
    "                                        lr_bu=learning_user,\n",
    "                                        lr_bi=learning_item)\n",
    "                    \n",
    "                    # Fit model\n",
    "                    model.fit(train_set)\n",
    "                    \n",
    "                    # Predict All Pairs of Users & Items that are NOT in the Trainset \n",
    "                    predictions = compute_ranking_predictions(basemodel, train, usercol='CustomerID', itemcol='StockCode', remove_seen=True)\n",
    "                    \n",
    "                    # Filter Top 10 \n",
    "                    top_10 = filter_top_n(predictions, 10)\n",
    "                    \n",
    "                    # Evaluate Recall at 10 \n",
    "                    eval_recall_10 = recall_at_k(test, top_10,col_user=\"CustomerID\", col_item=\"StockCode\",\n",
    "                                                col_rating=\"purchased\", col_prediction=\"prediction\", \n",
    "                                                relevancy_method=\"top_k\", k=10)\n",
    "\n",
    "                    print(\"recall at 10 for\", factors, \"factors: \\t\", eval_recall_10)\n",
    "                    factor_nr.append(factors)\n",
    "                    regulation_user.append(reg_user)\n",
    "                    regulation_item.append(reg_item)\n",
    "                    lr_user.append(learning_user)\n",
    "                    lr_item.append(learning_item)\n",
    "                    recall_10.append(eval_recall_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_param = {\n",
    "    \"factor\": factor_nr,\n",
    "    \"regulation_user\": regulation_user,\n",
    "    \"regulation_item\": regulation_item,\n",
    "    \"learning_rate_user\": lr_user,\n",
    "    \"learning_rate_item\": lr_item,\n",
    "    \"recall_10\": recall_10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>recall_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   factor  recall_10\n",
       "0      20       0.00\n",
       "1     200       0.00"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_param = pd.DataFrame(dict_param)\n",
    "df_param.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factor</th>\n",
       "      <th>recall_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>110.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>127.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>65.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>110.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>155.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       factor  recall_10\n",
       "count    2.00       2.00\n",
       "mean   110.00       0.00\n",
       "std    127.28       0.00\n",
       "min     20.00       0.00\n",
       "25%     65.00       0.00\n",
       "50%    110.00       0.00\n",
       "75%    155.00       0.00\n",
       "max    200.00       0.00"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_param.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17afcd9f6960de0a3656d2c4c5dd434deed0eab3cd38c55c3169df3bef50250d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
